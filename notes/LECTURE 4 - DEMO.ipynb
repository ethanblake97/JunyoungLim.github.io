{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Supervised Learning\n",
    "\n",
    "So far we have discussed the importance of data visualization and data preprocessing. These steps are important in preparing datasets for statistical analysis and machine learning. We will now start our machine learning section of the course. The main focus of this class is on a field of machine learning called __supervised learning__ and thus we will devote a significant portion of the remaining lecture series on this topic. \n",
    "\n",
    "In order to understand what supervised learning is, instead of explaining the theory right from the start, we will dive straight into an example (with accompanying code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning on the California housing dataset\n",
    "We will be using the diabetes dataset included in the datasets module in the sklearn package. This module includes several toy datasets that have been very well-studied in the past. It is often a good idea to start learning machine learning using these datasets, and students are encouraged to try out some if not all of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cali_data = sklearn.datasets.fetch_california_housing()\n",
    "\n",
    "description = cali_data.DESCR\n",
    "cali_features = pd.DataFrame(cali_data.data)\n",
    "cali_target = pd.Series(cali_data.target)\n",
    "\n",
    "cali_features.columns = cali_data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So notice that there are three parts of the dataset downloaded here: The __descriptions__, the __data__, and the __target__ variable.\n",
    "\n",
    "In many cases the target variable is usually part of the data portion, but the sklearn package conveniently has them as separate fields for the downloaded object. So what is the target variable? Let's say it is the variable that is the target of __predictions__. The characteristics of target variables will be discussed in a section later in this lecture. But for now, let's gather some more information from the data.\n",
    "\n",
    "\n",
    "The convenient part of using the datasets module is that usually datasets obtained using this API provides dataset descriptions. Let's look at this one's description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset.\n",
      "\n",
      "The original database is available from StatLib\n",
      "\n",
      "    http://lib.stat.cmu.edu/\n",
      "\n",
      "The data contains 20,640 observations on 9 variables.\n",
      "\n",
      "This dataset contains the average house value as target variable\n",
      "and the following input variables (features): average income,\n",
      "housing average age, average rooms, average bedrooms, population,\n",
      "average occupation, latitude, and longitude in that order.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "Statistics and Probability Letters, 33 (1997) 291-297.\n",
      "\n",
      "\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "print(cali_data.DESCR)\n",
    "print(cali_data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this dataset has 20,640 data points The features available are house age, lat, long, and Population and etc. We know that the target variable is house value. Also judging from this fact, we can reasonably expect to have the target variable be a non-categorical, continuous variable. Let's check that by doing a unique function on the target, and see what's going on. Another way we can see the target variable is a histogram (as we've discussed in lecture 3 as a method of visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14999  0.175    0.225   ...,  4.991    5.       5.00001]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdea42f3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unique values of target variable\n",
    "print(np.unique(cali_target))\n",
    "\n",
    "# histogram of target variable\n",
    "import matplotlib.pyplot as plt\n",
    "n, bins, patches = plt.hist(cali_target, 50, facecolor='green', alpha=0.75)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the target variable is a continuous variable roughly in the range of [0,5] interval(Although the big jump at 5 seems very suspicious). Why? well there seems to be a continuous distribution of data points along this interval. While this point will be elaborated upon later on, having a continuous target variable makes this a __regression__ problem, as opposed to a __classification__ problem. \n",
    "\n",
    "So let's run a simple regression model called __linear regression__. Where do we find this model? Well sklearn, of course! Let's import linear regression.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I'll separate the data into two partitions called a __training set__ and a __validation set__ (often this is denoted as the __test set__, but strictly speaking this isn't the correct term to use). The model will only be trained using the training set and then tested on the validation set, for which we already know the target variable values. This way we simulate and evaluate performance of our model a situation where the model is given new data without a target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, vaplidation split as 80% 20% of the data\n",
    "\n",
    "index = np.random.rand(len(cali_features)) < 0.8 \n",
    "\n",
    "train_features = cali_features[index]\n",
    "valid_features = cali_features[~index]\n",
    "\n",
    "train_target = cali_target[index]\n",
    "valid_target = cali_target[~index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the linear regression model we created two cells up to this setup, and then estimate its predictive power on the validation set. We fit using the training set (X corresponds to features and y corresponds to the target variable, and then generating predictions using the features of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5311031958372554"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression fit\n",
    "model = model.fit(X=train_features, y=train_target)\n",
    "\n",
    "# predict on validations using the validation features as input\n",
    "predictions = model.predict(X=valid_features)\n",
    "\n",
    "# generate a score for the effectiveness of model\n",
    "sklearn.metrics.mean_squared_error(y_true = valid_target, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are many different ways to compare the generated predictions, but for simplicity we will use one feature, which is the root mean-squared error, as defined below.\n",
    "\n",
    "![mean squared error](https://www.researchgate.net/profile/Alexandros_Karatzoglou/publication/221515860/figure/fig1/AS:339586132791298@1457975051470/Figure-1-Mean-Squared-Error-formula-used-to-evaluate-the-user-model.ppm)\n",
    "\n",
    "To explain, this is the __mean squared difference__ between the __predicted value__ and the __actual value__. Why we use this value will be explained later on, but it is a useful accuracy metric to gauge the effectiveness of a machine learning model. All that matters is that the lower this value - or in other words closer to 0 - the more this model is considered effective. \n",
    "\n",
    "So what does this all mean, and why did we do it in this step anyway?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Supervised Learning?\n",
    "\n",
    "Supervised learning is the process of learning an unknown relationship between a set of feature variables and a target variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
